{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory name",
			"defaultValue": "LearningADFKP"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/DF_Surrogate')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Union_Emp_DS",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "EmployeeDept_Output_DS",
								"type": "DatasetReference"
							},
							"name": "SurKey"
						}
					],
					"transformations": [
						{
							"name": "surrogateKey1"
						},
						{
							"name": "select1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          E_ID as string,",
						"          E_NAME as string,",
						"          D_ID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 keyGenerate(output(EMPLOYEE_KEY as long),",
						"     startAt: 10001L,",
						"     stepValue: 1L) ~> surrogateKey1",
						"surrogateKey1 select(mapColumn(",
						"          EMPLOYEE_KEY,",
						"          EmployeeID = E_ID,",
						"          Name = E_NAME,",
						"          DepartmentID = D_ID",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Key_Surrogate_Employees'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> SurKey"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/DF_Unpivot')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Vendor_DS",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "EmployeeDept_Output_DS",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "unpivot1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          P_ID as string,",
						"          Vendor as string,",
						"          Apples as string,",
						"          Oranges as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 unpivot(output(",
						"          FRUITS as string,",
						"          Count as string",
						"     ),",
						"     ungroupBy(P_ID,",
						"          Vendor),",
						"     lateral: true,",
						"     ignoreNullPivots: false) ~> unpivot1",
						"unpivot1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['UnPivot_Vendor'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/DF_ValidateSchema')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Vendor_DS",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "EmployeeDept_Output_DS",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [],
					"scriptLines": [
						"source(output(",
						"          P_ID as integer,",
						"          Vendor as string,",
						"          Apples as integer,",
						"          Oranges as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     preferredIntegralType: 'integer') ~> source1",
						"source1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Vendor_OP_VS'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow1')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Employee_DS",
								"type": "DatasetReference"
							},
							"name": "Employee"
						},
						{
							"dataset": {
								"referenceName": "Department_DS",
								"type": "DatasetReference"
							},
							"name": "Department"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "EmployeeDept_Output_DS",
								"type": "DatasetReference"
							},
							"name": "SinkEmpDept"
						}
					],
					"transformations": [
						{
							"name": "join1"
						},
						{
							"name": "join2"
						},
						{
							"name": "select1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          E_ID as string,",
						"          E_NAME as string,",
						"          D_ID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Employee",
						"source(output(",
						"          D_ID as string,",
						"          D_NAME as string,",
						"          D_HEAD as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Department",
						"Employee, Department join(Employee@D_ID == Department@D_ID,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"select1, Employee join(D_HEAD == Employee@E_ID,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join2",
						"join1 select(mapColumn(",
						"          E_ID,",
						"          E_NAME,",
						"          D_ID = Employee@D_ID,",
						"          D_NAME,",
						"          D_HEAD",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"join2 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['EmployeeDepartment2'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          E_ID = Employee@E_ID,",
						"          E_NAME = Employee@E_NAME,",
						"          D_ID = Employee@D_ID,",
						"          D_NAME,",
						"          D_HEAD,",
						"          DEPT_HEAD_NAME = Employee@E_NAME",
						"     ),",
						"     partitionBy('hash', 1)) ~> SinkEmpDept"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow1_Agg')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Employee_DS",
								"type": "DatasetReference"
							},
							"name": "Employee"
						},
						{
							"dataset": {
								"referenceName": "Department_DS",
								"type": "DatasetReference"
							},
							"name": "Department"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "EmployeeDept_Output_DS",
								"type": "DatasetReference"
							},
							"name": "SinkEmpDept"
						}
					],
					"transformations": [
						{
							"name": "join1"
						},
						{
							"name": "aggregate1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          E_ID as string,",
						"          E_NAME as string,",
						"          D_ID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Employee",
						"source(output(",
						"          D_ID as string,",
						"          D_NAME as string,",
						"          D_HEAD as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Department",
						"Employee, Department join(Employee@D_ID == Department@D_ID,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"join1 aggregate(groupBy(D_NAME),",
						"     EmployeeCount = count(E_ID),",
						"     partitionBy('hash', 1)) ~> aggregate1",
						"aggregate1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['EmployeeCountByDepartment'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          D_NAME,",
						"          EmployeeCount",
						"     ),",
						"     partitionBy('hash', 1)) ~> SinkEmpDept"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow1_Cond_Split')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Employee_DS",
								"type": "DatasetReference"
							},
							"name": "Employee"
						},
						{
							"dataset": {
								"referenceName": "Department_DS",
								"type": "DatasetReference"
							},
							"name": "Department"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "EmployeeDept_Output_DS",
								"type": "DatasetReference"
							},
							"name": "SinkEmpDept"
						},
						{
							"dataset": {
								"referenceName": "EmployeeDept_Output_DS",
								"type": "DatasetReference"
							},
							"name": "SINKCIVILEmployees"
						},
						{
							"dataset": {
								"referenceName": "EmployeeDept_Output_DS",
								"type": "DatasetReference"
							},
							"name": "SINKITEmployee"
						}
					],
					"transformations": [
						{
							"name": "join1"
						},
						{
							"name": "split1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          E_ID as string,",
						"          E_NAME as string,",
						"          D_ID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Employee",
						"source(output(",
						"          D_ID as string,",
						"          D_NAME as string,",
						"          D_HEAD as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Department",
						"Employee, Department join(Employee@D_ID == Department@D_ID,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"join1 split(equals(D_NAME,'CSE'),",
						"     D_NAME=='CIVIL',",
						"     equals(D_NAME,'IT'),",
						"     disjoint: false) ~> split1@(CseEmployees, CivilEmployees, ItEmployees, Others)",
						"split1@CseEmployees sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['1CSEEmployee'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          E_ID,",
						"          E_NAME,",
						"          D_NAME",
						"     ),",
						"     partitionBy('hash', 1)) ~> SinkEmpDept",
						"split1@CivilEmployees sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['2CIVILEmployees'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          E_ID,",
						"          E_NAME,",
						"          D_NAME",
						"     ),",
						"     partitionBy('hash', 1)) ~> SINKCIVILEmployees",
						"split1@ItEmployees sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['3ITEmployees'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          E_ID,",
						"          E_NAME,",
						"          D_NAME",
						"     ),",
						"     partitionBy('hash', 1)) ~> SINKITEmployee"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow1_Derived')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "SampleDS_DF",
								"type": "DatasetReference"
							},
							"name": "Employee"
						},
						{
							"dataset": {
								"referenceName": "Department_DS",
								"type": "DatasetReference"
							},
							"name": "Department"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "EmployeeDept_Output_DS",
								"type": "DatasetReference"
							},
							"name": "SinkEmpDept"
						}
					],
					"transformations": [
						{
							"name": "derivedColumn1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Index_ID as string,",
						"          User_Id as string,",
						"          First_Name as string,",
						"          Last_Name as string,",
						"          Sex as string,",
						"          Email as string,",
						"          Phone as string,",
						"          Date_of_birth as string,",
						"          Job_Title as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Employee",
						"source(output(",
						"          D_ID as string,",
						"          D_NAME as string,",
						"          D_HEAD as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Department",
						"Employee derive(AGE = currentDate()- toDate(Date_of_birth),",
						"          Gender = iif(Sex=='Male','M','F')) ~> derivedColumn1",
						"derivedColumn1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['SampleCustomer1'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          User_Id,",
						"          First_Name,",
						"          Date_of_birth,",
						"          Job_Title,",
						"          AGE,",
						"          Gender",
						"     ),",
						"     partitionBy('hash', 1)) ~> SinkEmpDept"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow1_copy1')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Employee_DS",
								"type": "DatasetReference"
							},
							"name": "Employee"
						},
						{
							"dataset": {
								"referenceName": "Department_DS",
								"type": "DatasetReference"
							},
							"name": "Department"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "EmployeeDept_Output_DS",
								"type": "DatasetReference"
							},
							"name": "SinkEmpDept"
						}
					],
					"transformations": [
						{
							"name": "join1"
						},
						{
							"name": "filter1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          E_ID as string,",
						"          E_NAME as string,",
						"          D_ID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Employee",
						"source(output(",
						"          D_ID as string,",
						"          D_NAME as string,",
						"          D_HEAD as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Department",
						"Employee, Department join(Employee@D_ID == Department@D_ID,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"join1 filter(D_NAME == 'CSE') ~> filter1",
						"filter1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['CSEDepartment'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          E_ID,",
						"          E_NAME,",
						"          D_ID = Employee@D_ID,",
						"          Dept_NAME = D_NAME,",
						"          Dept_HEAD = D_HEAD",
						"     ),",
						"     partitionBy('hash', 1)) ~> SinkEmpDept"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflowRank')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Emp_Gender_DS",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Export_Samples_Data",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "rank1"
						},
						{
							"name": "rank2"
						}
					],
					"scriptLines": [
						"source(output(",
						"          E_ID as string,",
						"          E_NAME as string,",
						"          D_ID as string,",
						"          Gender as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 rank(asc(D_ID, true),",
						"     output(RANK_ID as long)) ~> rank1",
						"rank1 rank(asc(D_ID, true),",
						"     output(Dense_Rank as long),",
						"     dense: true) ~> rank2",
						"rank2 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Rank_DR_Employee.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_Lookup')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Emp_New_DS",
								"type": "DatasetReference"
							},
							"name": "EmpNew"
						},
						{
							"dataset": {
								"referenceName": "Department_DS",
								"type": "DatasetReference"
							},
							"name": "Dept"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "EmployeeDept_Output_DS",
								"type": "DatasetReference"
							},
							"name": "Lookupoutput"
						}
					],
					"transformations": [
						{
							"name": "lookup1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          E_ID as string,",
						"          E_NAME as string,",
						"          D_ID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> EmpNew",
						"source(output(",
						"          D_ID as string,",
						"          D_NAME as string,",
						"          D_HEAD as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Dept",
						"EmpNew, Dept lookup(EmpNew@D_ID == Dept@D_ID,",
						"     multiple: false,",
						"     pickup: 'any',",
						"     broadcast: 'auto')~> lookup1",
						"lookup1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Lookup_Output_File'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> Lookupoutput"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_union')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Employee_DS",
								"type": "DatasetReference"
							},
							"name": "Emp1"
						},
						{
							"dataset": {
								"referenceName": "Emp2",
								"type": "DatasetReference"
							},
							"name": "Emp2"
						},
						{
							"dataset": {
								"referenceName": "Emp2",
								"type": "DatasetReference"
							},
							"name": "Emp3"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "EmployeeDept_Output_DS",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "union1"
						},
						{
							"name": "derivedColumn1"
						},
						{
							"name": "select1"
						},
						{
							"name": "sort1"
						},
						{
							"name": "derivedColumn2"
						},
						{
							"name": "derivedColumn3"
						},
						{
							"name": "derivedColumn4"
						}
					],
					"scriptLines": [
						"source(output(",
						"          E_ID as string,",
						"          E_NAME as string,",
						"          D_ID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Emp1",
						"source(output(",
						"          E_ID as string,",
						"          E_NAME as string,",
						"          D_ID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Emp2",
						"source(output(",
						"          E_ID as string,",
						"          E_NAME as string,",
						"          D_ID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Emp3",
						"derivedColumn4, derivedColumn3, derivedColumn2, select1 union(byName: true)~> union1",
						"Emp3 derive(E_NAME = concat(E_NAME, ' Stark'),",
						"          E_ID = toInteger(E_ID) + 10) ~> derivedColumn1",
						"derivedColumn1 select(mapColumn(",
						"          E_ID,",
						"          E_NAME,",
						"          D_ID",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"union1 sort(desc(E_NAME, true),",
						"     caseInsensitive: true) ~> sort1",
						"Emp3 derive(E_NAME = concat(substring(E_NAME,1,2),' Targerian'),",
						"          E_ID = toInteger(E_ID) + 20) ~> derivedColumn2",
						"Emp2 derive(E_ID = toInteger(E_ID)) ~> derivedColumn3",
						"Emp1 derive(E_ID = toInteger(E_ID)) ~> derivedColumn4",
						"sort1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['UnionEmployee'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/P_Stringify_DataFlow')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "DF_Stringify",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "DF_Stringify_Sample",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"source1": {},
									"SinkStringify": {
										"P_FileName": "Stringify_OP2.csv",
										"P_FolderName": {
											"value": "@pipeline().globalParameters.RootPath",
											"type": "Expression"
										}
									}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "None",
							"cacheSinks": {
								"firstRowOnly": true
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": [
					"Stringify"
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/ST_EVERY_5_HOURS')]",
			"type": "Microsoft.DataFactory/factories/triggers",
			"apiVersion": "2018-06-01",
			"properties": {
				"annotations": [],
				"runtimeState": "Started",
				"pipelines": [
					{
						"pipelineReference": {
							"referenceName": "P_LOAD_AZURE_EXPORT_TO_BLOB",
							"type": "PipelineReference"
						},
						"parameters": {}
					}
				],
				"type": "ScheduleTrigger",
				"typeProperties": {
					"recurrence": {
						"frequency": "Hour",
						"interval": 5,
						"startTime": "2024-07-14T17:26:00",
						"endTime": "2024-08-12T23:59:00",
						"timeZone": "India Standard Time"
					}
				}
			},
			"dependsOn": []
		}
	]
}